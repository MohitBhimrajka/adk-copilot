# ADK Copilot

An intelligent AI copilot and expert assistant for developers using the Google Agent Development Kit (ADK). Built with a sophisticated multi-agent architecture, ADK Copilot helps developers solve problems, generate code, and navigate the complexities of building applications with the Google ADK.

**[➡️ Watch the Demo Video Here](https://your-video-link.com)**

---

## Overview

ADK Copilot is designed specifically for developers working with the Google Agent Development Kit. It combines the power of multiple specialized AI agents to provide comprehensive assistance—from troubleshooting deployment issues to generating complete, production-ready code examples. Whether you're stuck on a technical problem or need help building a new agent, ADK Copilot is your intelligent pair programming partner.

## Agent Architecture

![ADK Copilot Architecture](architecture_diagram.png)

The system is orchestrated by a main `orchestrator_agent` which delegates tasks to the following specialists:

1.  **`ticket_analysis_agent`**: Analyzes the initial developer request and enriches it with structured data (urgency, category, complexity, summary).
2.  **`knowledge_retrieval_agent`**: Performs a semantic search against the official ADK documentation (ingested into a Vertex AI RAG Corpus) to find relevant guides, APIs, and best practices.
3.  **`db_retrieval_agent`**: Searches a BigQuery database of historical developer issues to find similar past problems and their resolutions.
4.  **`problem_solver_agent`**: Synthesizes all gathered context to provide detailed, step-by-step solutions for deployment, configuration, or development challenges.
5.  **`code_generator_agent`**: Generates complete, high-quality code examples, agents, and applications when developers need implementation assistance.

## Key Features

-   **Multi-Agent Architecture:** An Orchestrator agent manages a team of five specialist sub-agents, each with expertise in different aspects of ADK development.
-   **Intelligent Problem Solving:** Analyzes deployment issues, configuration problems, and technical errors with context-aware solutions.
-   **Advanced Code Generation:** Creates complete, annotated agent implementations, custom tools, and application architectures tailored to your specific requirements.
-   **RAG-Powered Knowledge Base:** Utilizes Vertex AI RAG to search a comprehensive, auto-generated knowledge base of the official Google ADK documentation.
-   **Historical Solutions Database:** Connects to a BigQuery database to find solutions from previously resolved developer issues, learning from past problems.
-   **Stateful, Multi-Turn Workflow:** Manages conversation state to ensure logical progression from problem identification to solution implementation.
-   **Interactive Development Process:** For complex requests, the system proposes an architecture or approach before generating code, improving accuracy and developer satisfaction.
-   **Automated Environment Setup:** A single script handles the creation of all necessary data, cloud storage, BigQuery tables, and the RAG corpus, making setup seamless.

> **Note on Knowledge Base Content:** The knowledge base used by this agent is generated by scraping the publicly available [Google ADK documentation website](https://google.github.io/adk-docs/). All content rights belong to the original authors. This project uses the content for demonstration and educational purposes in accordance with fair use principles. The scraped data is provided as-is and may not be perfectly formatted or up-to-date.

## Technologies Used

This project is built on a modern, cloud-native stack, leveraging the power of Google Cloud and open-source AI frameworks:

*   **Core Framework:** Google Agent Development Kit (ADK)
*   **Language:** Python 3.11+
*   **AI Models:** Google Gemini 2.5 Pro & 2.0 Flash (via Vertex AI)
*   **Data & Retrieval:**
    *   Vertex AI RAG (Retrieval-Augmented Generation)
    *   Google BigQuery (for vector search on historical data)
    *   Google Cloud Storage (for RAG document storage)
*   **Deployment:**
    *   Vertex AI Agent Engine (for production-style deployment)
    *   Google Cloud Run (for dev/demo deployment with UI)
*   **Tooling:** Poetry, GCloud SDK

## Setup and Installation

Follow these steps to set up the project environment and all necessary data backends.

### 1. Prerequisites

-   Python 3.11+
-   [Poetry](https://python-poetry.org/docs/) for dependency management.
-   A Google Cloud Project with the AI Platform API enabled.
-   The [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) installed and authenticated (`gcloud auth application-default login`).

### 2. Configure Environment Variables

Copy the example environment file. **This is a mandatory step.**

```bash
cp .env.example .env
```

Now, edit the newly created `.env` file with your specific Google Cloud project details.

```dotenv
# .env
GOOGLE_GENAI_USE_VERTEXAI=1
GOOGLE_CLOUD_PROJECT=your-gcp-project-id
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_CLOUD_STORAGE_BUCKET=your-gcp-project-id
RAG_CORPUS_NAME="" # This will be auto-populated by the setup script
BQ_PROJECT_ID=your-gcp-project-id
BQ_DATASET_ID=adk_copilot_dataset
CRM_API_KEY="your-crm-api-key-here" # Optional, not used in core logic
```

**Note:** The `GOOGLE_CLOUD_STORAGE_BUCKET` must be a globally unique name. Using your project ID as a prefix is a good practice to ensure uniqueness.

### 3. Install Dependencies

Use Poetry to create a virtual environment and install all required Python packages.

```bash
poetry install
```

### 4. Run the Automated Environment Setup

This final step runs a shell script that automates the entire backend setup process. It generates mock data and configures your Google Cloud services (BigQuery and RAG).

First, make the script executable:
```bash
chmod +x setup_environment.sh
```

Now, run the script:
```bash
./setup_environment.sh
```

This script will perform the following actions:
1.  **Scrape Docs:** Run `scripts/scrape_adk_docs.py` to build the `data/knowledge_base`.
2.  **Create Mock DB:** Run `scripts/create_mock_db.py` to generate `data/resolved_tickets.csv`.
3.  **Setup BigQuery:** Run `scripts/setup_bigquery.py` to create the dataset and table in your GCP project and upload the CSV data.
4.  **Setup RAG:** Run `scripts/setup_rag.py` to create a GCS bucket, upload the knowledge base, create a Vertex AI RAG Corpus, and **automatically write the new `RAG_CORPUS_NAME` back to your `.env` file.**

After this script completes, your entire backend and data infrastructure will be ready to use.

## Running the Agent

You can interact with the agent using the ADK's built-in web interface.

```bash
# Make sure you are in the project's virtual environment
# poetry shell

adk web
```

Navigate to `http://localhost:8000` in your browser and select the `adk_copilot` agent from the dropdown menu.

### Example Interactions

-   **Problem Solving:** "My deployment is failing with a 403 Permission Denied error when trying to deploy my agent to Vertex AI. I've checked my service account permissions but I'm still getting this error."
-   **Code Generation:** "Write me an agent that uses a custom tool to get the current weather and provides personalized clothing recommendations based on the forecast."
-   **Architecture Guidance:** "I need to build a multi-agent system that processes customer feedback. What's the best approach using ADK?"
-   **Debugging Help:** "My agent is running but the tools aren't being called correctly. Can you help me troubleshoot?"

## Findings & Learnings

Building this project was a deep dive into the practicalities of multi-agent system design. Here are our key takeaways:

1.  **The Orchestrator is a State Machine:** The most critical learning was that a robust orchestrator is essentially a state machine. By managing a `status` field (e.g., "New", "Analyzing", "Pending Solution") in the shared state, we could create a reliable, sequential, and fault-tolerant workflow. Without this, agents would fire unpredictably.
2.  **Isolate Specialized Tools:** Early on, we had issues mixing the `VertexAiRagRetrieval` tool with other custom tools in a single agent. The solution was architectural: create highly specialized "tool-runner" agents (like `knowledge_retrieval_agent`) whose only job is to expose one complex tool. This simplified the orchestrator's job and resolved API constraints.
3.  **Prompt Engineering is System Design:** The orchestrator's prompt isn't just an instruction; it's the central logic of the application. We spent significant time refining it to be deterministic, forcing a specific sequence of actions based on the current state. This was more effective than letting the model "decide" the entire workflow on its own.
4.  **Automation is Key for Judges:** We knew that a complex backend (BigQuery, RAG, GCS) would be hard for judges to set up. Investing time in the `setup_environment.sh` script was crucial to ensure our project was easily testable, a key requirement for the hackathon.

## Project Structure

A comprehensive overview of the repository structure:

```
adk-copilot/
├── adk_copilot/                    # Core source code for the agent system
│   ├── agent.py                    # Main orchestrator agent definition
│   ├── prompts.py                  # System prompts for all agents
│   ├── entities/                   # Data models and structures
│   │   ├── ticket.py              # SupportTicket Pydantic model
│   │   └── __init__.py
│   ├── sub_agents/                 # Specialized sub-agent implementations
│   │   ├── README.md              # Sub-agents documentation
│   │   ├── ticket_analysis/        # Analyzes and categorizes user requests
│   │   │   ├── agent.py
│   │   │   └── __init__.py
│   │   ├── knowledge_retrieval/    # RAG-based documentation search
│   │   │   ├── agent.py
│   │   │   └── __init__.py
│   │   ├── db_retrieval/          # BigQuery historical data search
│   │   │   ├── agent.py
│   │   │   └── __init__.py
│   │   ├── problem_solver/        # Synthesizes solutions from context
│   │   │   ├── agent.py
│   │   │   └── __init__.py
│   │   ├── code_generator/        # Generates code examples and implementations
│   │   │   ├── agent.py
│   │   │   └── __init__.py
│   │   └── __init__.py
│   ├── tools/                     # Custom Python function tools
│   │   ├── tools.py               # RAG search and BigQuery tools
│   │   ├── README.md              # Tools documentation
│   │   └── __init__.py
│   └── __init__.py
├── scripts/                       # Environment setup and data preparation
│   ├── README.md                  # Scripts documentation
│   ├── scrape_adk_docs.py         # Scrapes ADK documentation for knowledge base
│   ├── create_mock_db.py          # Generates mock historical ticket data
│   ├── setup_bigquery.py         # Creates BigQuery dataset and uploads data
│   └── setup_rag.py              # Sets up Vertex AI RAG corpus and GCS bucket
├── data/                          # Data files and knowledge base
│   ├── README.md                  # Data documentation
│   ├── knowledge_base/            # Scraped ADK documentation files
│   │   ├── adk_handbook.md        # Comprehensive ADK handbook
│   │   ├── adk-docs.md           # Main documentation file
│   │   ├── adk-docs_*.md         # Specific documentation sections
│   │   ├── *.txt                 # Additional knowledge files
│   │   └── rag.txt               # RAG-specific documentation
│   ├── pdf/                      # PDF versions of knowledge base files
│   └── resolved_tickets.csv       # Mock historical support tickets
├── deployment/                    # Deployment scripts and configurations
│   ├── README.md                  # Deployment documentation
│   ├── deploy_agent_engine.py    # Deploy to Vertex AI Agent Engine
│   └── deploy_cloud_run.sh       # Deploy to Cloud Run with web UI
├── eval/                          # Evaluation and testing
│   ├── test_eval.py              # Evaluation test script
│   └── data/                     # Test data
│       └── conversation.test.json # Sample conversation for testing
├── dist/                          # Build artifacts (created by poetry build)
├── setup_environment.sh          # Main setup script (runs all setup steps)
├── pyproject.toml                # Python project configuration and dependencies
├── poetry.lock                   # Locked dependency versions
├── README.md                     # This file - project documentation
├── LICENSE                       # Project license
└── .gitignore                    # Git ignore patterns
```

## Disclaimer

This is a demonstration project and is not intended for production use without further testing and hardening.
